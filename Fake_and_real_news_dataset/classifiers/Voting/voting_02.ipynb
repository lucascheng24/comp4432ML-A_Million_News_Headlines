{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YEMaITXDEnLR"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "yfcRcosQEvVe",
        "outputId": "b8aff631-e56a-457b-8fe8-fd2ac61a327c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.657124</td>\n",
              "      <td>50.442482</td>\n",
              "      <td>20.871874</td>\n",
              "      <td>-54.531494</td>\n",
              "      <td>20.362791</td>\n",
              "      <td>28.577585</td>\n",
              "      <td>-1.906657</td>\n",
              "      <td>28.021065</td>\n",
              "      <td>-24.411823</td>\n",
              "      <td>-19.387388</td>\n",
              "      <td>...</td>\n",
              "      <td>-49.060287</td>\n",
              "      <td>-3.104522</td>\n",
              "      <td>27.967051</td>\n",
              "      <td>-30.539959</td>\n",
              "      <td>0.434239</td>\n",
              "      <td>36.554264</td>\n",
              "      <td>-1.757592</td>\n",
              "      <td>37.968136</td>\n",
              "      <td>-14.561114</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73.660179</td>\n",
              "      <td>76.221085</td>\n",
              "      <td>-40.807030</td>\n",
              "      <td>-82.814301</td>\n",
              "      <td>28.292801</td>\n",
              "      <td>36.778252</td>\n",
              "      <td>-1.909100</td>\n",
              "      <td>49.479527</td>\n",
              "      <td>-79.806595</td>\n",
              "      <td>27.742567</td>\n",
              "      <td>...</td>\n",
              "      <td>-107.097870</td>\n",
              "      <td>-24.814592</td>\n",
              "      <td>-22.166080</td>\n",
              "      <td>3.848902</td>\n",
              "      <td>36.787331</td>\n",
              "      <td>59.989563</td>\n",
              "      <td>-6.423959</td>\n",
              "      <td>21.630405</td>\n",
              "      <td>-88.683472</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-13.957203</td>\n",
              "      <td>50.162762</td>\n",
              "      <td>60.824032</td>\n",
              "      <td>-16.521429</td>\n",
              "      <td>-84.106873</td>\n",
              "      <td>33.965801</td>\n",
              "      <td>-24.306961</td>\n",
              "      <td>112.798645</td>\n",
              "      <td>-90.984291</td>\n",
              "      <td>-23.109505</td>\n",
              "      <td>...</td>\n",
              "      <td>-37.652954</td>\n",
              "      <td>39.876980</td>\n",
              "      <td>101.627777</td>\n",
              "      <td>-16.215570</td>\n",
              "      <td>-2.601095</td>\n",
              "      <td>74.666214</td>\n",
              "      <td>-34.334938</td>\n",
              "      <td>4.400374</td>\n",
              "      <td>-16.785315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34.285301</td>\n",
              "      <td>24.369213</td>\n",
              "      <td>37.394283</td>\n",
              "      <td>-56.808426</td>\n",
              "      <td>-13.195957</td>\n",
              "      <td>27.064581</td>\n",
              "      <td>-27.190607</td>\n",
              "      <td>45.300884</td>\n",
              "      <td>-38.357361</td>\n",
              "      <td>-21.576128</td>\n",
              "      <td>...</td>\n",
              "      <td>-37.443409</td>\n",
              "      <td>8.713444</td>\n",
              "      <td>20.008799</td>\n",
              "      <td>-13.551638</td>\n",
              "      <td>16.853464</td>\n",
              "      <td>48.484596</td>\n",
              "      <td>-13.077551</td>\n",
              "      <td>5.347030</td>\n",
              "      <td>-43.575981</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.285158</td>\n",
              "      <td>182.228394</td>\n",
              "      <td>3.545697</td>\n",
              "      <td>-74.310005</td>\n",
              "      <td>-46.353405</td>\n",
              "      <td>27.703939</td>\n",
              "      <td>-23.581633</td>\n",
              "      <td>136.181381</td>\n",
              "      <td>-75.572617</td>\n",
              "      <td>-49.096653</td>\n",
              "      <td>...</td>\n",
              "      <td>-108.719910</td>\n",
              "      <td>51.889614</td>\n",
              "      <td>156.074570</td>\n",
              "      <td>9.806570</td>\n",
              "      <td>61.040123</td>\n",
              "      <td>24.597773</td>\n",
              "      <td>-46.054447</td>\n",
              "      <td>-51.063011</td>\n",
              "      <td>-56.279831</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26766</th>\n",
              "      <td>-71.454414</td>\n",
              "      <td>56.266552</td>\n",
              "      <td>-52.882614</td>\n",
              "      <td>-45.946815</td>\n",
              "      <td>-243.017334</td>\n",
              "      <td>76.435471</td>\n",
              "      <td>-80.246399</td>\n",
              "      <td>212.383789</td>\n",
              "      <td>-183.680710</td>\n",
              "      <td>-156.889847</td>\n",
              "      <td>...</td>\n",
              "      <td>-57.277454</td>\n",
              "      <td>78.127159</td>\n",
              "      <td>146.414536</td>\n",
              "      <td>-44.106407</td>\n",
              "      <td>59.677574</td>\n",
              "      <td>120.351700</td>\n",
              "      <td>-139.349457</td>\n",
              "      <td>35.773731</td>\n",
              "      <td>6.932467</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26767</th>\n",
              "      <td>-0.284165</td>\n",
              "      <td>25.422646</td>\n",
              "      <td>2.497849</td>\n",
              "      <td>-8.947376</td>\n",
              "      <td>-36.106369</td>\n",
              "      <td>29.048079</td>\n",
              "      <td>-8.172162</td>\n",
              "      <td>28.610073</td>\n",
              "      <td>-23.188131</td>\n",
              "      <td>-27.730436</td>\n",
              "      <td>...</td>\n",
              "      <td>4.322698</td>\n",
              "      <td>22.755190</td>\n",
              "      <td>8.053110</td>\n",
              "      <td>2.871661</td>\n",
              "      <td>8.147329</td>\n",
              "      <td>12.612817</td>\n",
              "      <td>-6.104894</td>\n",
              "      <td>10.478649</td>\n",
              "      <td>2.183957</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26768</th>\n",
              "      <td>71.339561</td>\n",
              "      <td>16.005495</td>\n",
              "      <td>51.056477</td>\n",
              "      <td>-179.901749</td>\n",
              "      <td>-14.259531</td>\n",
              "      <td>126.382141</td>\n",
              "      <td>-4.463017</td>\n",
              "      <td>42.901329</td>\n",
              "      <td>53.434349</td>\n",
              "      <td>-14.907699</td>\n",
              "      <td>...</td>\n",
              "      <td>-106.613243</td>\n",
              "      <td>-39.113091</td>\n",
              "      <td>48.542309</td>\n",
              "      <td>-67.660194</td>\n",
              "      <td>58.561333</td>\n",
              "      <td>206.557541</td>\n",
              "      <td>-90.538963</td>\n",
              "      <td>154.817764</td>\n",
              "      <td>-92.831696</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26769</th>\n",
              "      <td>81.606827</td>\n",
              "      <td>-113.467224</td>\n",
              "      <td>-3.810923</td>\n",
              "      <td>-238.568436</td>\n",
              "      <td>70.856094</td>\n",
              "      <td>87.432976</td>\n",
              "      <td>53.989868</td>\n",
              "      <td>111.472473</td>\n",
              "      <td>-73.990349</td>\n",
              "      <td>42.114433</td>\n",
              "      <td>...</td>\n",
              "      <td>-40.093098</td>\n",
              "      <td>107.691345</td>\n",
              "      <td>-5.296010</td>\n",
              "      <td>-85.728683</td>\n",
              "      <td>78.135361</td>\n",
              "      <td>180.972107</td>\n",
              "      <td>-158.033691</td>\n",
              "      <td>8.803612</td>\n",
              "      <td>-97.057518</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26770</th>\n",
              "      <td>-9.061508</td>\n",
              "      <td>51.307201</td>\n",
              "      <td>1.799478</td>\n",
              "      <td>-21.316128</td>\n",
              "      <td>33.891590</td>\n",
              "      <td>-0.983956</td>\n",
              "      <td>0.430483</td>\n",
              "      <td>29.928816</td>\n",
              "      <td>-33.132679</td>\n",
              "      <td>9.734270</td>\n",
              "      <td>...</td>\n",
              "      <td>-63.536953</td>\n",
              "      <td>41.002930</td>\n",
              "      <td>136.605927</td>\n",
              "      <td>-37.271595</td>\n",
              "      <td>66.403702</td>\n",
              "      <td>45.280163</td>\n",
              "      <td>-61.338646</td>\n",
              "      <td>74.322266</td>\n",
              "      <td>5.017591</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26771 rows × 251 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1          2           3           4           5  \\\n",
              "0      19.657124   50.442482  20.871874  -54.531494   20.362791   28.577585   \n",
              "1      73.660179   76.221085 -40.807030  -82.814301   28.292801   36.778252   \n",
              "2     -13.957203   50.162762  60.824032  -16.521429  -84.106873   33.965801   \n",
              "3      34.285301   24.369213  37.394283  -56.808426  -13.195957   27.064581   \n",
              "4       8.285158  182.228394   3.545697  -74.310005  -46.353405   27.703939   \n",
              "...          ...         ...        ...         ...         ...         ...   \n",
              "26766 -71.454414   56.266552 -52.882614  -45.946815 -243.017334   76.435471   \n",
              "26767  -0.284165   25.422646   2.497849   -8.947376  -36.106369   29.048079   \n",
              "26768  71.339561   16.005495  51.056477 -179.901749  -14.259531  126.382141   \n",
              "26769  81.606827 -113.467224  -3.810923 -238.568436   70.856094   87.432976   \n",
              "26770  -9.061508   51.307201   1.799478  -21.316128   33.891590   -0.983956   \n",
              "\n",
              "               6           7           8           9  ...         241  \\\n",
              "0      -1.906657   28.021065  -24.411823  -19.387388  ...  -49.060287   \n",
              "1      -1.909100   49.479527  -79.806595   27.742567  ... -107.097870   \n",
              "2     -24.306961  112.798645  -90.984291  -23.109505  ...  -37.652954   \n",
              "3     -27.190607   45.300884  -38.357361  -21.576128  ...  -37.443409   \n",
              "4     -23.581633  136.181381  -75.572617  -49.096653  ... -108.719910   \n",
              "...          ...         ...         ...         ...  ...         ...   \n",
              "26766 -80.246399  212.383789 -183.680710 -156.889847  ...  -57.277454   \n",
              "26767  -8.172162   28.610073  -23.188131  -27.730436  ...    4.322698   \n",
              "26768  -4.463017   42.901329   53.434349  -14.907699  ... -106.613243   \n",
              "26769  53.989868  111.472473  -73.990349   42.114433  ...  -40.093098   \n",
              "26770   0.430483   29.928816  -33.132679    9.734270  ...  -63.536953   \n",
              "\n",
              "              242         243        244        245         246         247  \\\n",
              "0       -3.104522   27.967051 -30.539959   0.434239   36.554264   -1.757592   \n",
              "1      -24.814592  -22.166080   3.848902  36.787331   59.989563   -6.423959   \n",
              "2       39.876980  101.627777 -16.215570  -2.601095   74.666214  -34.334938   \n",
              "3        8.713444   20.008799 -13.551638  16.853464   48.484596  -13.077551   \n",
              "4       51.889614  156.074570   9.806570  61.040123   24.597773  -46.054447   \n",
              "...           ...         ...        ...        ...         ...         ...   \n",
              "26766   78.127159  146.414536 -44.106407  59.677574  120.351700 -139.349457   \n",
              "26767   22.755190    8.053110   2.871661   8.147329   12.612817   -6.104894   \n",
              "26768  -39.113091   48.542309 -67.660194  58.561333  206.557541  -90.538963   \n",
              "26769  107.691345   -5.296010 -85.728683  78.135361  180.972107 -158.033691   \n",
              "26770   41.002930  136.605927 -37.271595  66.403702   45.280163  -61.338646   \n",
              "\n",
              "              248        249  target  \n",
              "0       37.968136 -14.561114       0  \n",
              "1       21.630405 -88.683472       0  \n",
              "2        4.400374 -16.785315       1  \n",
              "3        5.347030 -43.575981       0  \n",
              "4      -51.063011 -56.279831       0  \n",
              "...           ...        ...     ...  \n",
              "26766   35.773731   6.932467       1  \n",
              "26767   10.478649   2.183957       0  \n",
              "26768  154.817764 -92.831696       0  \n",
              "26769    8.803612 -97.057518       0  \n",
              "26770   74.322266   5.017591       1  \n",
              "\n",
              "[26771 rows x 251 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataPath = '../../preprocess_data_set/newsData_ratio8_2.csv'\n",
        "\n",
        "df_train = pd.read_csv(dataPath)\n",
        "\n",
        "# randomly shuffle the rows\n",
        "df_train = df_train.sample(frac=1, random_state=42)\n",
        "df_train = df_train.reset_index()\n",
        "df_train = df_train.drop('index', axis=1)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gXJCMnVLEwur"
      },
      "outputs": [],
      "source": [
        "train_y = df_train['target']\n",
        "train_x = df_train.drop(columns=['target'])\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.3,random_state=109) # 70% training and 30% test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "dh_iJRVAEyi1",
        "outputId": "37e41e19-5c56-40ac-9b32-855e7c40900f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;dt&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;knn&#x27;, KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;dt&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;knn&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('dt', DecisionTreeClassifier()),\n",
              "                             ('knn', KNeighborsClassifier())])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hard Voting\n",
        "LogisticModel = LogisticRegression()\n",
        "DecisionTreeModel = DecisionTreeClassifier()\n",
        "KNeighborsModel = KNeighborsClassifier()\n",
        "\n",
        "HardVotingModel = VotingClassifier(\n",
        "    voting = 'hard',\n",
        "    estimators=[\n",
        "        ('lr',LogisticModel),\n",
        "        ('dt',DecisionTreeModel),\n",
        "        ('knn',KNeighborsModel)\n",
        "    ])\n",
        "HardVotingModel.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Dj-Yg1E6iN",
        "outputId": "73deff2f-0901-4a80-f8ec-251fdc8515cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      6581\n",
            "           1       0.90      0.98      0.94      1451\n",
            "\n",
            "    accuracy                           0.98      8032\n",
            "   macro avg       0.95      0.98      0.96      8032\n",
            "weighted avg       0.98      0.98      0.98      8032\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = HardVotingModel.predict(X_test)\n",
        "print(metrics.classification_report(y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "OG7NNnGuK-7p",
        "outputId": "9ca21465-2ba7-4fd5-96cc-c2496710ecbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;dt&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;dt&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('dt', DecisionTreeClassifier()),\n",
              "                             ('knn', KNeighborsClassifier())],\n",
              "                 voting='soft')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Soft Voting\n",
        "LogisticModel = LogisticRegression()\n",
        "DecisionTreeModel = DecisionTreeClassifier()\n",
        "KNeighborsModel = KNeighborsClassifier()\n",
        "\n",
        "SoftVotingModel = VotingClassifier(\n",
        "    voting = 'soft',\n",
        "    estimators=[\n",
        "        ('lr',LogisticModel),\n",
        "        ('dt',DecisionTreeModel),\n",
        "        ('knn',KNeighborsModel)\n",
        "    ])\n",
        "SoftVotingModel.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_tsNUa4LCe4",
        "outputId": "0bbb8c1a-e0ff-4b56-aac3-936ef564cf64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      6580\n",
            "           1       0.90      0.98      0.94      1452\n",
            "\n",
            "    accuracy                           0.98      8032\n",
            "   macro avg       0.95      0.98      0.96      8032\n",
            "weighted avg       0.98      0.98      0.98      8032\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = SoftVotingModel.predict(X_test)\n",
        "print(metrics.classification_report(y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross Validation Scores:  [0.97703081 0.97571909 0.97553231 0.97366455 0.98057527]\n",
            "Average CV Score:  0.9765044067683106\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "k_folds = KFold(n_splits = 5)\n",
        "\n",
        "SoftVotingModel_cv = VotingClassifier(\n",
        "    voting = 'soft',\n",
        "    estimators=[\n",
        "        ('lr',LogisticModel),\n",
        "        ('dt',DecisionTreeModel),\n",
        "        ('knn',KNeighborsModel)\n",
        "    ]\n",
        ")\n",
        "\n",
        "scores = cross_val_score(SoftVotingModel_cv, train_x, train_y, cv = k_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
